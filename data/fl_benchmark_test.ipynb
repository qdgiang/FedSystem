{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"\"))\n",
    "from dataset.advanced_benchmark.constants import MEAN, STD\n",
    "from dataset.advanced_benchmark.datasets import DATASETS\n",
    "import torch\n",
    "from typing import List, Type, Dict\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/giang/Desktop/FedSystem/data/fl_benchmark_test.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/giang/Desktop/FedSystem/data/fl_benchmark_test.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(partition))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/giang/Desktop/FedSystem/data/fl_benchmark_test.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(partition\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/giang/Desktop/FedSystem/data/fl_benchmark_test.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(partition[\u001b[39m\"\u001b[39m\u001b[39mseparation\u001b[39m\u001b[39m\"\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partition' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(partition))\n",
    "print(partition.keys())\n",
    "print(type(partition[\"separation\"]))\n",
    "print(partition[\"separation\"].keys())\n",
    "print(type(partition[\"separation\"][\"train\"]))\n",
    "print(len(partition[\"separation\"][\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_data(partition_id: int, name: str):\n",
    "    dir = os.path.abspath(\"\")\n",
    "    try:\n",
    "        partition_path = f\"{dir}/dataset/advanced_benchmark/{name}_federated.pkl\"\n",
    "        with open(partition_path, \"rb\") as f:\n",
    "            partition = pickle.load(f)\n",
    "    except:\n",
    "        raise FileNotFoundError(f\"Dataset not found\")\n",
    "\n",
    "    data_indices: List[List[int]] = partition[\"data_indices\"]\n",
    "\n",
    "    general_data_transform = transforms.Compose(\n",
    "            [transforms.Normalize(MEAN[name], STD[name])]\n",
    "        )\n",
    "    general_target_transform = transforms.Compose([])\n",
    "    train_data_transform = transforms.Compose([])\n",
    "    train_target_transform = transforms.Compose([])\n",
    "\n",
    "    my_dataset = DATASETS[name](\n",
    "            root=f\"{dir}/dataset/advanced_benchmark/{name}\",\n",
    "            args=None,\n",
    "            general_data_transform=general_data_transform,\n",
    "            general_target_transform=general_target_transform,\n",
    "            train_data_transform=train_data_transform,\n",
    "            train_target_transform=train_target_transform,\n",
    "        )\n",
    "\n",
    "    trainset: Subset = Subset(\n",
    "        dataset=my_dataset, \n",
    "        indices=data_indices[partition_id][\"train\"]\n",
    "    )\n",
    "    valset: Subset = Subset(\n",
    "        dataset=my_dataset, \n",
    "        indices=data_indices[partition_id][\"test\"]\n",
    "    )\n",
    "    trainloader = DataLoader(trainset, batch_size = 32, shuffle=True)\n",
    "    valloader = DataLoader(valset, batch_size=32, shuffle=True)\n",
    "\n",
    "    return trainloader, None, valloader, None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/giang/Desktop/FedSystem/data/dataset/advanced_benchmark/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [02:24<00:00, 1178651.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/giang/Desktop/FedSystem/data/dataset/advanced_benchmark/cifar10/cifar-10-python.tar.gz to /home/giang/Desktop/FedSystem/data/dataset/advanced_benchmark/cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "a, b, c, d = get_client_data(0, \"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([84, 3, 32, 32])\n",
      "torch.Size([84])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for s,d in a:\n",
    "    print(s.shape)\n",
    "    print(d.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flwr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
